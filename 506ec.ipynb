{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "load-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (370703, 24)\n",
      "Test Shape: (92676, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        id                         trans_num  trans_date trans_time  \\\n",
       " 0   308467  26ad750c2ff71f32631b58913582d70a  2024-01-10   06:49:39   \n",
       " 1   261578  fea9c1efe3f2b97f27ad0ab5409ec861  2024-01-06   02:37:50   \n",
       " 2      341  2ae350b982be840f3666273e0c2f3a05  2024-01-18   21:40:21   \n",
       " 3  1147639  bbdd8adfc0a34ed0e817f809193c85c0  2024-01-21   16:20:15   \n",
       " 4   314152  fc7756004dc2a9bc450eb894a670b804  2024-01-21   19:36:26   \n",
       " \n",
       "     unix_time        category     amt            cc_num    first     last  \\\n",
       " 0  1704887379        misc_pos  188.38      676355457570   Andrea  Johnson   \n",
       " 1  1704526670     grocery_pos  102.63   377178373574671   Rhonda   Chavez   \n",
       " 2  1705632021   entertainment    1.62  3599292013370451  Stephen     Khan   \n",
       " 3  1705872015  health_fitness    5.64  3594292572430345   Justin   Reilly   \n",
       " 4  1705883786  health_fitness   97.09  4867547663675548    Alice   Duarte   \n",
       " \n",
       "    ...    zip      lat      long city_pop                          job  \\\n",
       " 0  ...  62220  38.5127  -89.9847    95666        Accounting technician   \n",
       " 1  ...  21784  39.4567  -76.9696    37941            Designer, graphic   \n",
       " 2  ...  49735  45.0125  -84.6723    19515  Careers information officer   \n",
       " 3  ...  44256  41.1404  -81.8584    62039         Merchandiser, retail   \n",
       " 4  ...  91501  34.1862 -118.3009   106841               Prison officer   \n",
       " \n",
       "           dob                          merchant  merch_lat  merch_long  \\\n",
       " 0  1983-05-26          fraud_Turcotte-Halvorson  39.268874  -89.273447   \n",
       " 1  1976-12-03         fraud_Schamberger-O'Keefe  39.961495  -76.707640   \n",
       " 2  1999-08-24  fraud_Nicolas, Hills and McGlynn  44.393561  -85.342323   \n",
       " 3  1930-02-24                 fraud_Cormier LLC  40.283764  -81.639361   \n",
       " 4  1951-10-15                 fraud_Kulas Group  35.149704 -118.087440   \n",
       " \n",
       "   is_fraud  \n",
       " 0        0  \n",
       " 1        0  \n",
       " 2        0  \n",
       " 3        0  \n",
       " 4        0  \n",
       " \n",
       " [5 rows x 24 columns],\n",
       "        id                         trans_num  trans_date trans_time  \\\n",
       " 0   52329  2e6b34f2047158280fd5b50cb5249fcc  2024-01-27   13:17:44   \n",
       " 1   92215  5e4c36e1e6f1838f0afe1ed83d42d48e  2024-01-31   21:12:51   \n",
       " 2  107070  de58b3413be0b956c261b8e756006b5d  2024-01-24   23:06:59   \n",
       " 3  117508  63e5e8954b6954121fb9395b8fb87ec3  2024-01-15   14:42:37   \n",
       " 4  525132  f0acdc291ca35b61a873060e419b20a5  2024-01-30   22:02:41   \n",
       " \n",
       "     unix_time       category     amt            cc_num    first     last  ...  \\\n",
       " 0  1706379464      kids_pets   13.00    30184874050384   Edward  Mueller  ...   \n",
       " 1  1706753571         travel   25.64  3560293989785735     Ryan   Reeves  ...   \n",
       " 2  1706155619           home   99.48   213175392060268  Gregory   Graham  ...   \n",
       " 3  1705347757    grocery_pos  972.26  2720994415033785  Jessica    Carey  ...   \n",
       " 4  1706670161  personal_care  165.04      639070744995    Corey   Rogers  ...   \n",
       " \n",
       "   state    zip      lat      long  city_pop  \\\n",
       " 0    NY  11230  40.6225  -73.9650   2504700   \n",
       " 1    CA  92504  33.9315 -117.4119    419138   \n",
       " 2    KY  42629  36.9680  -85.0968      4953   \n",
       " 3    TX  75571  33.1808  -94.7639      2846   \n",
       " 4    NJ   7022  40.8170  -74.0000     13835   \n",
       " \n",
       "                                     job         dob  \\\n",
       " 0                Leisure centre manager  1955-12-17   \n",
       " 1                             Mudlogger  1940-06-22   \n",
       " 2                  Engineer, automotive  1993-03-18   \n",
       " 3       Geophysicist/field seismologist  1958-06-30   \n",
       " 4  Accountant, chartered public finance  1972-04-13   \n",
       " \n",
       "                              merchant  merch_lat  merch_long  \n",
       " 0     fraud_Lowe, Dietrich and Erdman  40.707029  -74.027386  \n",
       " 1               fraud_Johnston-Casper  34.344545 -117.348319  \n",
       " 2  fraud_Gutmann, McLaughlin and Wiza  37.493843  -85.224136  \n",
       " 3   fraud_Schoen, Kuphal and Nitzsche  32.238558  -94.085343  \n",
       " 4                fraud_Sporer-Keebler  40.957527  -73.328707  \n",
       " \n",
       " [5 rows x 23 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Display basic information\n",
    "print('Train Shape:', train.shape)\n",
    "print('Test Shape:', test.shape)\n",
    "train.head(), test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feature-engineering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        id  category     amt  gender  state      lat      long  city_pop  job  \\\n",
       " 0   308467         9  188.38       0     14  38.5127  -89.9847     95666    6   \n",
       " 1   261578         4  102.63       0     20  39.4567  -76.9696     37941  160   \n",
       " 2      341         0    1.62       1     22  45.0125  -84.6723     19515   80   \n",
       " 3  1147639         5    5.64       1     35  41.1404  -81.8584     62039  377   \n",
       " 4   314152         5   97.09       0      4  34.1862 -118.3009    106841  451   \n",
       " \n",
       "    merch_lat  merch_long  is_fraud  age  trans_count  geo_distance  \n",
       " 0  39.268874  -89.273447         0   40           37      1.038114  \n",
       " 1  39.961495  -76.707640         0   47           61      0.568719  \n",
       " 2  44.393561  -85.342323         0   24           24      0.912149  \n",
       " 3  40.283764  -81.639361         0   93           36      0.884196  \n",
       " 4  35.149704 -118.087440         0   72           29      0.986866  ,\n",
       "        id  category     amt  gender  state      lat      long  city_pop  job  \\\n",
       " 0   52329         7   13.00       1     34  40.6225  -73.9650   2504700  345   \n",
       " 1   92215        13   25.64       1      4  33.9315 -117.4119    419138  385   \n",
       " 2  107070         6   99.48       1     17  36.9680  -85.0968      4953  197   \n",
       " 3  117508         4  972.26       0     43  33.1808  -94.7639      2846  276   \n",
       " 4  525132        10  165.04       1     31  40.8170  -74.0000     13835    5   \n",
       " \n",
       "    merch_lat  merch_long  age  trans_count  geo_distance  \n",
       " 0  40.707029  -74.027386   68            7      0.105058  \n",
       " 1  34.344545 -117.348319   83            3      0.417910  \n",
       " 2  37.493843  -85.224136   30            6      0.541041  \n",
       " 3  32.238558  -94.085343   65            1      1.161146  \n",
       " 4  40.957527  -73.328707   51            6      0.685844  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Derive age from dob\n",
    "train['age'] = pd.to_datetime('2024-01-01') - pd.to_datetime(train['dob'])\n",
    "train['age'] = train['age'].dt.days // 365\n",
    "test['age'] = pd.to_datetime('2024-01-01') - pd.to_datetime(test['dob'])\n",
    "test['age'] = test['age'].dt.days // 365\n",
    "\n",
    "# Transaction velocity\n",
    "train['trans_count'] = train.groupby('cc_num')['trans_num'].transform('count')\n",
    "test['trans_count'] = test.groupby('cc_num')['trans_num'].transform('count')\n",
    "\n",
    "# Geospatial distance\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return np.sqrt((lat1 - lat2)**2 + (lon1 - lon2)**2)\n",
    "\n",
    "train['geo_distance'] = calculate_distance(train['lat'], train['long'], train['merch_lat'], train['merch_long'])\n",
    "test['geo_distance'] = calculate_distance(test['lat'], test['long'], test['merch_lat'], test['merch_long'])\n",
    "\n",
    "# Encode categorical variables\n",
    "cat_columns = ['category', 'job', 'state', 'gender']\n",
    "encoder = LabelEncoder()\n",
    "for col in cat_columns:\n",
    "    train[col] = encoder.fit_transform(train[col].astype(str))\n",
    "    test[col] = encoder.transform(test[col].astype(str))\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_cols = ['trans_num', 'trans_date', 'trans_time', 'unix_time', 'cc_num', 'dob', 'first', 'last', 'street', 'city', 'zip', 'merchant']\n",
    "train = train.drop(columns=drop_cols)\n",
    "test = test.drop(columns=drop_cols)\n",
    "\n",
    "train.head(), test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "train-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.25701\n",
      "[1]\tvalidation_0-logloss:0.21418\n",
      "[2]\tvalidation_0-logloss:0.18577\n",
      "[3]\tvalidation_0-logloss:0.16723\n",
      "[4]\tvalidation_0-logloss:0.15406\n",
      "[5]\tvalidation_0-logloss:0.14487\n",
      "[6]\tvalidation_0-logloss:0.13816\n",
      "[7]\tvalidation_0-logloss:0.13250\n",
      "[8]\tvalidation_0-logloss:0.12892\n",
      "[9]\tvalidation_0-logloss:0.12585\n",
      "[10]\tvalidation_0-logloss:0.12296\n",
      "[11]\tvalidation_0-logloss:0.12141\n",
      "[12]\tvalidation_0-logloss:0.12015\n",
      "[13]\tvalidation_0-logloss:0.11872\n",
      "[14]\tvalidation_0-logloss:0.11648\n",
      "[15]\tvalidation_0-logloss:0.11534\n",
      "[16]\tvalidation_0-logloss:0.11288\n",
      "[17]\tvalidation_0-logloss:0.11262\n",
      "[18]\tvalidation_0-logloss:0.11227\n",
      "[19]\tvalidation_0-logloss:0.11056\n",
      "[20]\tvalidation_0-logloss:0.11047\n",
      "[21]\tvalidation_0-logloss:0.10929\n",
      "[22]\tvalidation_0-logloss:0.10870\n",
      "[23]\tvalidation_0-logloss:0.10851\n",
      "[24]\tvalidation_0-logloss:0.10829\n",
      "[25]\tvalidation_0-logloss:0.10814\n",
      "[26]\tvalidation_0-logloss:0.10726\n",
      "[27]\tvalidation_0-logloss:0.10699\n",
      "[28]\tvalidation_0-logloss:0.10692\n",
      "[29]\tvalidation_0-logloss:0.10692\n",
      "[30]\tvalidation_0-logloss:0.10695\n",
      "[31]\tvalidation_0-logloss:0.10692\n",
      "[32]\tvalidation_0-logloss:0.10667\n",
      "[33]\tvalidation_0-logloss:0.10625\n",
      "[34]\tvalidation_0-logloss:0.10607\n",
      "[35]\tvalidation_0-logloss:0.10611\n",
      "[36]\tvalidation_0-logloss:0.10578\n",
      "[37]\tvalidation_0-logloss:0.10577\n",
      "[38]\tvalidation_0-logloss:0.10577\n",
      "[39]\tvalidation_0-logloss:0.10574\n",
      "[40]\tvalidation_0-logloss:0.10573\n",
      "[41]\tvalidation_0-logloss:0.10567\n",
      "[42]\tvalidation_0-logloss:0.10554\n",
      "[43]\tvalidation_0-logloss:0.10552\n",
      "[44]\tvalidation_0-logloss:0.10555\n",
      "[45]\tvalidation_0-logloss:0.10555\n",
      "[46]\tvalidation_0-logloss:0.10553\n",
      "[47]\tvalidation_0-logloss:0.10549\n",
      "[48]\tvalidation_0-logloss:0.10551\n",
      "[49]\tvalidation_0-logloss:0.10553\n",
      "[50]\tvalidation_0-logloss:0.10543\n",
      "[51]\tvalidation_0-logloss:0.10544\n",
      "[52]\tvalidation_0-logloss:0.10505\n",
      "[53]\tvalidation_0-logloss:0.10463\n",
      "[54]\tvalidation_0-logloss:0.10459\n",
      "[55]\tvalidation_0-logloss:0.10375\n",
      "[56]\tvalidation_0-logloss:0.10376\n",
      "[57]\tvalidation_0-logloss:0.10376\n",
      "[58]\tvalidation_0-logloss:0.10375\n",
      "[59]\tvalidation_0-logloss:0.10364\n",
      "[60]\tvalidation_0-logloss:0.10366\n",
      "[61]\tvalidation_0-logloss:0.10370\n",
      "[62]\tvalidation_0-logloss:0.10373\n",
      "[63]\tvalidation_0-logloss:0.10351\n",
      "[64]\tvalidation_0-logloss:0.10348\n",
      "[65]\tvalidation_0-logloss:0.10347\n",
      "[66]\tvalidation_0-logloss:0.10333\n",
      "[67]\tvalidation_0-logloss:0.10335\n",
      "[68]\tvalidation_0-logloss:0.10337\n",
      "[69]\tvalidation_0-logloss:0.10340\n",
      "[70]\tvalidation_0-logloss:0.10336\n",
      "[71]\tvalidation_0-logloss:0.10335\n",
      "[72]\tvalidation_0-logloss:0.10336\n",
      "[73]\tvalidation_0-logloss:0.10338\n",
      "[74]\tvalidation_0-logloss:0.10337\n",
      "[75]\tvalidation_0-logloss:0.10328\n",
      "[76]\tvalidation_0-logloss:0.10334\n",
      "[77]\tvalidation_0-logloss:0.10332\n",
      "[78]\tvalidation_0-logloss:0.10332\n",
      "[79]\tvalidation_0-logloss:0.10327\n",
      "[80]\tvalidation_0-logloss:0.10329\n",
      "[81]\tvalidation_0-logloss:0.10332\n",
      "[82]\tvalidation_0-logloss:0.10314\n",
      "[83]\tvalidation_0-logloss:0.10322\n",
      "[84]\tvalidation_0-logloss:0.10323\n",
      "[85]\tvalidation_0-logloss:0.10322\n",
      "[86]\tvalidation_0-logloss:0.10324\n",
      "[87]\tvalidation_0-logloss:0.10324\n",
      "[88]\tvalidation_0-logloss:0.10321\n",
      "[89]\tvalidation_0-logloss:0.10328\n",
      "[90]\tvalidation_0-logloss:0.10328\n",
      "[91]\tvalidation_0-logloss:0.10333\n",
      "[92]\tvalidation_0-logloss:0.10339\n",
      "[93]\tvalidation_0-logloss:0.10326\n",
      "[94]\tvalidation_0-logloss:0.10304\n",
      "[95]\tvalidation_0-logloss:0.10309\n",
      "[96]\tvalidation_0-logloss:0.10308\n",
      "[97]\tvalidation_0-logloss:0.10309\n",
      "[98]\tvalidation_0-logloss:0.10314\n",
      "[99]\tvalidation_0-logloss:0.10279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     65681\n",
      "           1       0.87      0.75      0.81      8460\n",
      "\n",
      "    accuracy                           0.96     74141\n",
      "   macro avg       0.92      0.87      0.89     74141\n",
      "weighted avg       0.96      0.96      0.96     74141\n",
      "\n",
      "ROC AUC: 0.9812694662212009\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "X = train.drop('is_fraud', axis=1)\n",
    "y = train['is_fraud']\n",
    "\n",
    "# Split for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Train XGBoost Model\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print('ROC AUC:', roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "predict-and-save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the test dataset\n",
    "# Ensure the test dataset matches the training dataset's columns\n",
    "test_features = test.drop(columns=['id'], errors='ignore')  # Drop 'id' column if present\n",
    "missing_cols = [col for col in X.columns if col not in test_features.columns]  # Check for missing columns\n",
    "\n",
    "# Add any missing columns with default values\n",
    "for col in missing_cols:\n",
    "    test_features[col] = 0  # Use default value (0)\n",
    "\n",
    "# Ensure the column order matches the training dataset\n",
    "test_features = test_features[X.columns]\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = model.predict(test_features)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = sample_submission.copy()\n",
    "submission['is_fraud'] = test_predictions\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file saved as 'submission.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
